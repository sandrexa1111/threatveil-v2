1) Gemini (LLM reasoning)

Purpose  
Turn raw signals into a plain-English summary + 2–3 prioritized actions for non-technical users.

Base  
https://generativelanguage.googleapis.com/v1beta  
Endpoint:  
POST /models/gemini-3:generateContent?key={GEMINI_API_KEY}  
Auth: API key in query string (or Authorization header, depending on client).

Recommended request shape
{
  "contents": [
    {
      "parts": [
        {
          "text": "SYSTEM: You are Veil Analyst. Be concise and factual. Explain top risks in <=120 words and give 2–3 prioritized steps.\nUSER: <JSON signals + risk_score + risk_likelihood_30d/90d>"
        }
      ]
    }
  ],
  "generationConfig": {
    "temperature": 0.2,
    "topK": 40,
    "topP": 0.9,
    "maxOutputTokens": 300
  },
  "safetySettings": []
}

Expected response (relevant part)
{
  "candidates": [
    {
      "content": {
        "parts": [
          { "text": "Final summary <=120 words + 2–3 actions" }
        ]
      }
    }
  ]
}

Backoff & caching

- On 429 / 5xx: exponential backoff (e.g. ~200ms → 600ms → 1500–2500ms + jitter).
- Cache summaries for 12h for identical {signals, risk_score, likelihoods} bundles.
  - Compute a stable hash *before* adding timestamps.

Redaction & safety

- Strip emails, tokens, API keys, and secrets from the prompt before sending.
- Never send raw secrets, .env contents, or full file bodies to Gemini.
- If `candidates` is missing/empty → return deterministic fallback summary.
- If model returns longer content, clamp yourself to 120 words.

---

2) Supabase Postgres (persistence)

Purpose  
Store scans, AI scans, summaries, and cached API responses.

Connection  
DATABASE_URL=postgresql+psycopg2://user:pass@host:5432/db

Core tables (conceptual)

-- scans
id uuid pk,
domain text,
github_org text null,
risk_score int,
risk_likelihood_30d float8,
risk_likelihood_90d float8,
categories_json jsonb,
signals_json jsonb,
summary text,
raw_payload jsonb,
created_at timestamptz default now();

-- scan_ai
id uuid pk,
scan_id uuid fk -> scans.id,
ai_score int,
ai_tools_detected jsonb,
ai_key_leaks jsonb,
ai_agents_detected jsonb,
ai_summary text,
created_at timestamptz default now();

-- cache
key text primary key,
value jsonb not null,
expires_at timestamptz not null;

Patterns

- Use `pool_pre_ping=True` on the SQLAlchemy engine.
- Keep transactions short; wrap writes in context managers and rollback on errors.
- Store evidence inside `signals_json` entries (see Evidence Envelope below).
- Add indexes later as needed (e.g. `(domain, created_at DESC)` and `scan_ai.scan_id` unique).

---

3) GitHub (public code & AI footprint)

Purpose  
Discover public leaks (keys, prompts, .env), AI libraries, agent frameworks, and AI config files for a target org. **Public data only**.

Base  
https://api.github.com  
Auth:  
Authorization: token {GITHUB_TOKEN} (fine-grained, read-only public repos).

Primary endpoint  
GET /search/code

Example query (keep tight to control rate use)
q=org:{ORG} (filename:.env OR "OPENAI_API_KEY" OR "GEMINI_API_KEY" OR "system prompt" OR "-----BEGIN PRIVATE KEY-----")  
per_page=10

Response (subset)
{
  "total_count": 2,
  "items": [
    {
      "name": "...",
      "path": "...",
      "repository": { "full_name": "org/repo" },
      "html_url": "https://github.com/org/repo/blob/..."
    }
  ]
}

Usage patterns

- Use separate helper(s) to:
  - Detect AI libraries/frameworks (openai, langchain, etc.).
  - Detect AI-related files (*.prompt, *.ai, *.llm.yaml, ai-config.json).
  - Detect agent frameworks (CrewAI, AutoGen, LangGraph).
  - Detect key leak indicators (OPENAI_API_KEY, GEMINI_API_KEY, etc.).

Backoff & caching

- Respect `X-RateLimit-Remaining` and `Retry-After` headers where present.
- On 429/5xx: exponential backoff and *graceful* degradation (partial results).
- Cache by `(org, query)` for 24h; store only metadata (repo, path, html_url).
- Never store entire file contents in the DB.

Legal & security

- Public information only; never attempt to bypass auth or access private repos.
- Present links (`html_url`) and guidance, not raw contents.
- Provide remediation advice (rotate keys, add secret scanning to CI/CD).

---

4) Vulners (CVE & security intel)

Purpose  
Map detected technology tokens (e.g., "nginx", "wordpress 6.4") to known CVEs and severities.

Base  
https://vulners.com/api/v3  
Endpoints  
- POST /search/lucene/ — for product/version CVE search  
- POST /search/id/ — for specific CVE lookups (optional)

Auth  
X-Vulners-Api-Key: {VULNERS_API_KEY}

Query strategy

- Derive tokens from HTTP headers/meta:
  - `Server`, `X-Powered-By`, meta `generator`, etc.
- Normalize tokens like:
  - "nginx 1.18"
  - "wordpress 6.4"
  - Fallback to product-only (“nginx”, “wordpress”) if version is unknown.

Example request
{
  "query": "wordpress 6.4 AND type:cve",
  "size": 10
}

Response (subset)
{
  "data": {
    "search": [
      {
        "_source": {
          "id": "CVE-2024-XXXX",
          "cvss": { "score": 7.5 },
          "title": "...",
          "description": "...",
          "published": "2024-05-10T...",
          "href": "https://vulners.com/cve/CVE-2024-XXXX"
        }
      }
    ]
  }
}

Severity mapping

- `cvss.score >= 7.0` → high (software category)
- `4.0–6.9` → medium
- `< 4.0` or missing → low

Backoff & caching

- On 429/5xx: exponential backoff and return *empty CVE list* on repeated failure.
- Cache results for 24h per normalized token string.
- Deduplicate CVEs by `id`.

---

5) Lakera Guard (optional prompt/PII/safety)

Purpose  
Score inputs/outputs for prompt injection, PII exposure, and safety.  
*Optional*, can be integrated later for Horizon / chat safeguards.

Base  
https://api.lakera.ai  
Endpoint  
POST /v2/guard  
Auth  
Authorization: Bearer {LAKERA_API_KEY}

Request example
{
  "input": "User prompt or model output to evaluate",
  "detectors": ["prompt_injection", "pii", "safety"]
}

Response (subset)
{
  "results": {
    "prompt_injection": { "score": 0.83, "label": "high" },
    "pii": { "score": 0.10, "label": "low" },
    "safety": { "score": 0.12, "label": "low" }
  }
}

Usage patterns

- Pre-LLM: evaluate risky prompts before sending them to Gemini.
- Post-LLM: inspect model outputs for PII/safety issues.
- Cache classifications for 1–6h for identical text.
- Never cache raw secrets; only store hashes or high-level results.

---

6) AlienVault OTX (optional threat enrichment)

Purpose  
Enrich domain with community threat intel signals: pulses, malware tags, etc.  
Considered a *weak* signal unless corroborated by config issues or CVEs.

Base  
https://otx.alienvault.com/api/v1  
Auth  
X-OTX-API-KEY: {OTX_API_KEY}

Useful endpoint

Domain intel:  
GET /indicators/domain/{domain}/general

Response (subset)
{
  "indicator": "example.com",
  "pulse_info": {
    "count": 3,
    "pulses": [
      { "name":"...", "id":"...", "modified":"..." }
    ]
  }
}

Integration

- Derive a soft signal:
  - e.g., `otx_pulse_count > 0` → add low/medium severity enrichment signal.
- Cache for 24h per domain.
- OTX failure must not affect overall scan success.

---

8) Resend (email reports, optional)

Purpose  
Send PDF reports and (later) weekly summaries via email.  
Not required for scanning; optional feature.

Base  
https://api.resend.com  
Endpoint  
POST /emails  
Auth  
Authorization: Bearer {RESEND_API_KEY}

Attachment flow

- Base64-encode PDF bytes returned by report generation.
- Include as attachment with proper filename.

Example request
{
  "from": "ThreatVeil <reports@yourdomain>",
  "to": ["owner@client.com"],
  "subject": "Your ThreatVeil Risk Report",
  "html": "<p>Attached is your latest ThreatVeil report.</p>",
  "attachments": [
    {
      "filename": "threatveil-report.pdf",
      "content": "<base64>"
    }
  ]
}

Tips

- Verify sender domain before production use.
- Add unsubscribe / manage-alerts link in future.
- Retry on 5xx; log message id for audit.

---

Evidence Envelope (standard signal schema)

Every signal should follow a consistent, auditable structure:

{
  "id": "http_header_hsts_missing",
  "type": "http" | "tls" | "dns" | "ct" | "cve" | "github" | "otx" | "ai_guard",
  "detail": "HSTS missing on root path",
  "severity": "high" | "medium" | "low",
  "category": "network" | "software" | "data_exposure" | "ai_integration",
  "evidence": {
    "source": "https",               // or "vulners", "github", "otx", "lakera"
    "observed_at": "2025-11-13T12:00:00Z",
    "url": "https://example.com/",   // if applicable
    "raw": {
      "header_sample": {
        "Strict-Transport-Security": null
      }
    }
  }
}

This makes summaries explainable, testable, and investor-safe.

---

Retry / Backoff Template (Python)

```python
import asyncio, random, httpx

async def with_backoff(fn, *, retries=3, base_ms=200, max_ms=2500):
    for i in range(retries):
        try:
            return await fn()
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429 or 500 <= e.response.status_code < 600:
                delay = min(max_ms, base_ms * (2 ** i)) + random.randint(0, 200)
                await asyncio.sleep(delay / 1000)
            else:
                raise
        except (httpx.ReadTimeout, httpx.ConnectTimeout):
            delay = min(max_ms, base_ms * (2 ** i)) + random.randint(0, 200)
            await asyncio.sleep(delay / 1000)
    # final attempt (may still fail; caller must handle)
    return await fn()
